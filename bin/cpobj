#!/usr/bin/env python

import os
import sys
import logging
import boto.s3
from boto.s3.connection import S3Connection
from boto.s3.connection import OrdinaryCallingFormat
import progressbar

## Load our local library functions
sys.path.insert(0, "%s/.." % os.path.dirname(sys.argv[0]))
import umobj
from umobj.utils import umobj_logging, umobj_init_keyboard_interrupt, \
    umobj_get_bucket_key_pair_from_string
from umobj.key import create_directory
from umobj.multipart import MultiPart

pbar = None


def usage():
    prog_name = os.path.basename(sys.argv[0])
    usage_string = """
NAME
    %s - Copy files to and from an S3 compatible object store

SYNOPSIS
    %s [OPTION]... SRC [SRC]+ BUCKET[:DEST]

    %s [OPTION]... BUCKET[:SRC] DEST

OPTIONS SUMMARY

    -a, --access_key <access_key>  Object store access key
    -s, --secret_key <secret_key>  Object store secret key
    -S, --server <server>          Object store server name
    -P, --port <port>              Object store server port [Default: 443]
    -m, --multipart                Instantiate multipart transfer [Default: no]
    -r, --recursive                Copy files recursively [Default: no]
    -f, --force                    Force overwrite files in download mode
    -V, --verbose                  Verbose mode
        --version                  Print version
    -D, --debug                    Debug mode
    -h, --help

OPTIONS
    access_key  - Your Access Key ID.  If not supplied, boto will
                  use the value of the environment variable OBJ_ACCESS_KEY_ID.
    secret_key  - Your Secret Access Key.  If not supplied, will use the value
                  of the environment variable OBJ_SECRET_ACCESS_KEY.
    server      - The object storage server you want to connect to.  This can
                  be overridden by the OBJ_SERVER environment variable.
    BUCKET      - The bucket that is to be used for this copy operation.  This
                  is necessary on one and only one of the SRC and DEST
                  arguments.
    SRC         - Local file system directory/file or object store key.  A
                  directory is allowed for uploads if recursive is turned on,
                  and is allowed for download.
    DEST        - Local file system directory/file or object store key.  A
                  directory is allowed for downloads.

""" % (prog_name, prog_name, prog_name)
    print usage_string
    sys.exit()


def transfer_stats(trans_bytes, total_bytes):
    try:
        pbar.update(trans_bytes)
    except AssertionError, e:
        print e


def upload_file(key, filename, progress=True):
    global pbar
    if os.path.islink(filename):
        logging.warning('Skipping %s, symlink.' % filename)
        return -1
    if not os.path.isfile(filename):
        logging.warning('Skipping %s, unknown file type.' % filename)
        return -1
    file_size = os.stat(filename).st_size
    logging.info("Uploading %s with %d bytes." % (filename, file_size))
    if file_size is 0:
        if progress:
            pbar = progressbar.ProgressBar(maxval=100)
            pbar.start()
        key.set_contents_from_filename(filename)
        if progress:
            pbar.update(100)
            pbar.finish()
        return 0
    if progress:
        pbar = progressbar.ProgressBar(maxval=file_size)
        pbar.start()
    try:
        if progress:
            key.set_contents_from_filename(filename, cb=transfer_stats,
                                           num_cb=100)
        else:
            key.set_contents_from_filename(filename)
    except IOError, e:
        print e
        return 0
    if progress:
        pbar.finish()
    return file_size


def download_file(key, filename, progress=True):
    logging.info("Downloading %s with %d bytes." % (filename, key.size))
    global pbar
    if key.size is 0:
        pbar = progressbar.ProgressBar(maxval=100)
        pbar.start()
        if filename.endswith('/'):
            if not os.path.isdir(filename):
                logging.info("Creating directory %s." % filename)
                os.makedirs(filename)
            else:
                logging.info("Directory %s already exists, skipping." %
                             filename)
        else:
            key.get_contents_to_filename(filename)
        pbar.update(100)
        pbar.finish()
        return
    pbar = progressbar.ProgressBar(maxval=key.size)
    pbar.start()
    if os.path.isdir(filename):
        filename = filename + os.sep + os.path.basename(key.name)
    f = open(filename, 'w')
    key.get_contents_to_file(f, cb=transfer_stats, num_cb=100)
    f.close()
    pbar.finish()


def cpobj_download(access_key, secret_key, server, bucket_name, dest, key_name,
                   recursive=False, multi=False):
    bucket = obj.get_bucket(bucket_name)
    if recursive:
        logging.info("Starting recursive download %s to %s prefix %s" %
                     (bucket.name, dest, key_name))
        if not os.path.isdir(dest):
            logging.error("DEST %s is not a directory." % dest)
            usage()
        else:
            for key in bucket.list(prefix=key_name):
                filename = dest.rstrip(os.sep) + os.sep + key.name
                logging.info("Downloading key %s (%d) to %s" %
                             (key, key.size, filename))
                if multi and key.size > 5 * 1024 * 1024:
                    m = MultiPart(access_key, secret_key, server, port)
                    m.start_download(bucket_name, key.name, dest)
                else:
                    download_file(key, filename)
    else:
        if not key_name:
            logging.error("Must specify a key to download or use " +
                          "recusive option")
            usage()
        if os.path.isfile(dest) and not force:
            logging.error("File %s already exists " % dest +
                          "please force flag to overwrite.")
            usage()
        else:
            key = bucket.get_key(key_name)
            if key is None:
                logging.error("Key does not exist or if this is a prefix" +
                              " you need to specify recusive, %s" % key_name)
                return
            ## only multipart if we specify and the key is >5MB
            if multi and key.size > 5 * 1024 * 1024:
                logging.info("Downloading key %s (%d) to %s" %
                             (key, key.size, dest))
                m = MultiPart(access_key, secret_key, server, port)
                m.start_download(bucket_name, key_name, dest)
            else:
                key = bucket.get_key(key_name)
                download_file(key, dest)


def cpobj_upload(access_key, secret_key, server, bucket_name, src, dest_name,
                 recursive=False, multi=False):
    bucket = obj.get_bucket(bucket_name)
    size = os.stat(src).st_size
    policy = bucket.get_acl()
    if recursive and os.path.isdir(src):
        if dest_name:
            prefix = dest_name.rstrip(os.sep) + '/'
            logging.info("Create directory %s" % prefix)
            dir_key = bucket.new_key(prefix)
            create_directory(dir_key)
            logging.debug("Applying bucket policy %s" % policy)
            dir_key.set_acl(policy)
        else:
            prefix = ''
        for root, dirs, files in os.walk(src.rstrip(os.sep)):
            directory = prefix + root
            logging.info("Create directory %s" % directory)
            dir_key = bucket.new_key(directory + '/')
            create_directory(dir_key)
            logging.debug("Applying bucket policy %s" % policy)
            dir_key.set_acl(policy)
            for f in files:
                filename = root + os.sep + f
                size = os.stat(filename).st_size
                keyname = prefix + root + '/' + f
                logging.info("Upload key %s from file %s" %
                             (keyname, filename))
                if (multi and size > 0) or (size > (1024*1024*1024)):
                    m = MultiPart(access_key, secret_key, server, port)
                    m.start_upload(bucket_name, keyname, filename, policy)
                else:
                    key = bucket.new_key(keyname)
                    res = upload_file(key, filename)
                    if res >= 0:
                        logging.debug("Applying bucket policy %s" % policy)
                        key.set_acl(policy)
    else:
        if os.path.isdir(src):
            logging.warning("Skipping directory %s, " % src +
                            "use the recursive option.")
            return
        if not os.path.isfile(src):
            logging.error("File %s does not exist." % src)
            return
        if dest_name:
            current_path = ''
            for dir_part in dest_name.lstrip(os.sep).split(os.sep):
                current_path = current_path + dir_part + '/'
                key = bucket.new_key(current_path)
                create_directory(key)
                logging.debug("Applying bucket policy %s" % policy)
                key.set_acl(policy)
                key_name = current_path + os.path.basename(src)
        else:
            key_name = os.path.basename(src)
        if multi or (size > (1024*1024*1024)):
            logging.info("Starting a multipart upload.")
            m = MultiPart(access_key, secret_key, server, port)
            m.start_upload(bucket_name, key_name, src, policy)
        else:
            key = bucket.new_key(key_name)
            res = upload_file(key, src)
            if res >= 0:
                logging.debug("Applying bucket policy %s" % policy)
                key.set_acl(policy)


if __name__ == "__main__":
    import getopt

    umobj_init_keyboard_interrupt()

    try:
        opts, args = getopt.getopt(sys.argv[1:],
                                   'a:b:s:S:P:hmrfVD',
                                   ['access_key=', 'secret_key=',
                                    'server=', 'port=', 'multipart',
                                    'help', 'recursive', 'force',
                                    'verbose', 'debug', 'version'])
    except getopt.GetoptError, err:
        print str(err)  # will print something like "option -a not recognized"
        usage()

    force = False
    multi = False
    level = logging.WARNING
    access_key = None
    secret_key = None
    bucket_name = None
    try:
        server = os.environ['OBJ_SERVER']
    except:
        server = 'obj.umiacs.umd.edu'
    port = 443
    recursive = False

    for o, a in opts:
        if o in ('-h', '--help'):
            usage()
            sys.exit()
        if o in ('-a', '--access_key'):
            access_key = a
        if o in ('-s', '--secret_key'):
            secret_key = a
        if o in ('-b', '--bucket'):
            bucket_name = a
        if o in ('-S', '--server'):
            server = a
        if o in ('-P', '--port'):
            port = a
        if o in ('-m', '--multipart'):
            multi = True
        if o in ('-r', '--recursive'):
            recursive = True
        if o in ('-f', '--force'):
            force = True
        if o in ('-V', '--verbose'):
            level = logging.INFO
        if o in ('--version'):
            print umobj.__version__
            sys.exit()
        if o in ('-D', '--debug'):
            level = logging.DEBUG

    umobj_logging(level)

    logging.info("Using server %s" % server)
    logging.info("Running %s" % sys.argv)

    if access_key is None:
        try:
            access_key = os.environ['OBJ_ACCESS_KEY_ID']
        except:
            logging.error("Please provide access_key")
            usage()
    if secret_key is None:
        try:
            secret_key = os.environ['OBJ_SECRET_ACCESS_KEY']
        except:
            logging.error("Please provide secret_key")
            usage()

    obj = S3Connection(host=server, port=port, is_secure=True,
                       aws_access_key_id=access_key,
                       aws_secret_access_key=secret_key,
                       calling_format=OrdinaryCallingFormat())

    if len(args) < 2:
        usage()

    src = args[0]
    dest = args[-1]
    upload = False
    download = False
    src_bucket_name, src_key_name = \
        umobj_get_bucket_key_pair_from_string(src)
    dest_bucket_name, dest_key_name = \
        umobj_get_bucket_key_pair_from_string(dest)
    logging.debug("SRC Bucket Name: %s" % src_bucket_name)
    logging.debug("SRC Key Name: %s" % src_key_name)
    logging.debug("DEST Bucket Name: %s" % dest_bucket_name)
    logging.debug("DEST Key Name: %s" % dest_key_name)

    if ':' in dest:
        if ':' in src:
            if not os.path.exists(src):
                logging.error("Can not copy from a bucket to a bucket.")
                usage()
        bucket_name = dest_bucket_name
        dest_name = dest_key_name
        upload = True
        logging.info("Upload mode with bucket %s" % bucket_name)
        if dest_name:
            logging.info("Uploading to the prefix %s." % dest_name)
        logging.info("Uploading files %s." % args[0:-1])
    else:
        if ':' in src:
            if len(args) > 2:
                logging.error("Uploads only support a single BUCKET:SRC " +
                              "and DEST.")
                usage()
            bucket_name = src_bucket_name
            key_name = src_key_name
            download = True
            logging.info("Download mode with bucket %s." % bucket_name)
            if key_name:
                logging.info("Downloading with the key name/prefix %s." %
                             key_name)
            logging.info("Downloading to the local directory %s." % dest)
        else:
            logging.error("You need to provide a bucket in either SRC " +
                          "or DEST.")
            usage()

    try:
        bucket = obj.get_bucket(bucket_name)
    except boto.exception.S3ResponseError, e:
        logging.error("Unable to access bucket %s, %s." %
                      (bucket_name, e.error_code))
        sys.exit()

    if upload:
        for source in args[0:-1]:
            cpobj_upload(access_key, secret_key, server, bucket_name, source,
                         dest_name, recursive, multi)
    if download:
        cpobj_download(access_key, secret_key, server, bucket_name, dest,
                       key_name, recursive, multi)
